# <img src="anubis.png" alt="Anubis" width="32" height="32" style="vertical-align: middle; display: inline-block; margin-right: 8px;"/> Anubis Projeto - Requisitos

## DescriÃ§Ã£o

O Anubis Ã© um microserviÃ§o responsÃ¡vel pela orquestraÃ§Ã£o do envio de dados de alunos pagantes para APIs de instituiÃ§Ãµes de ensino superior, como Kroton e EstÃ¡cio. Ele gerencia o fluxo de inscriÃ§Ãµes vindas do Quero Bolsa e dos novos marketplaces (Ead.com, Guia da Carreira e Mundo Vestibular), organizando os payloads e registrando logs estruturados com o status das tentativas, alÃ©m de implementar mecanismos automÃ¡ticos de retry para falhas temporÃ¡rias.

O escopo do serviÃ§o nÃ£o inclui o envio de leads do Quero CaptaÃ§Ã£o, alunos pagantes de outros produtos da Qeevo, agendamento de envios ou interface para reenvio manual de falhas. O foco estÃ¡ na integraÃ§Ã£o eficiente e segura dos dados de alunos pagantes entre os sistemas internos e as APIs das instituiÃ§Ãµes parceiras.


## Modelo de Dados (ER Diagram)

ğŸ“Š Diagrama Entidade-Relacionamento

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
erDiagram
  SUBSCRIPTIONS }o--|| INTEGRATIONS : "belongs_to integration"
  INTEGRATIONS ||--o{ SUBSCRIPTIONS : "has_many subscriptions"
  
  SUBSCRIPTIONS }o--|| INTEGRATION_FILTERS : "belongs_to integration_filter"
  INTEGRATION_FILTERS ||--o{ SUBSCRIPTIONS : "has_many subscriptions"
  
  INTEGRATIONS ||--o{ INTEGRATION_FILTERS : "has_many integration_filters"
  INTEGRATION_FILTERS }o--|| INTEGRATIONS : "belongs_to integration"
  
  INTEGRATIONS ||--o{ INTEGRATION_TOKENS : "has_many integration_tokens"
  INTEGRATION_TOKENS }o--|| INTEGRATIONS : "belongs_to integration"
  
  SUBSCRIPTIONS ||--o{ SUBSCRIPTION_EVENTS : "has_many subscription_events"
  SUBSCRIPTION_EVENTS }o--|| SUBSCRIPTIONS : "belongs_to subscription"

  INTEGRATIONS {
    integer id PK
    string name "ğŸ“‹ Integration Name"
    string type "ğŸ”§ Integration Type"
    string key "ğŸ”‘ API Key"
    integer interval "â±ï¸ Sync Interval (minutes)"
    timestamp created_at
    timestamp updated_at
  }
  
  INTEGRATION_FILTERS {
    integer id PK
    integer integration_id FK "ğŸ”— Integration Reference"
    json filter "ğŸ¯ Filter Configuration"
    string type "ğŸ“ Filter Type"
    boolean enabled "âœ… Is Active"
    timestamp created_at
    timestamp updated_at
  }
  
  SUBSCRIPTIONS {
    integer id PK
    integer integration_id FK "ğŸ”Œ Integration Reference"
    integer integration_filter_id FK "ğŸ¯ Filter Reference"
    integer order_id "ğŸ“¦ Order ID"
    string origin "ğŸŒ Data Source"
    string cpf "ğŸ‘¤ Student CPF"
    json payload "ğŸ“„ Student Data"
    string status "ğŸ“Š Processing Status"
    timestamp sent_at "ğŸ“¤ Sent Timestamp"
    timestamp checked_at "ğŸ‘€ Last Check"
    timestamp scheduled_to "â° Scheduled For"
    timestamp created_at
    timestamp updated_at
  }
  
  INTEGRATION_TOKENS {
    integer id PK
    integer integration_id FK "ğŸ”— Integration Reference"
    string key "ğŸ” Token Key"
    string value "ğŸ« Token Value"
    timestamp valid_until "â³ Expiration Date"
    timestamp created_at
    timestamp updated_at
  }
  
  SUBSCRIPTION_EVENTS {
    integer id PK
    integer subscription_id FK "ğŸ“¦ Subscription Reference"
    string status "ğŸ“ˆ Event Status"
    string operation_name "âš™ï¸ Operation Type"
    string error_message "âŒ Error Details"
    json request "ğŸ“¤ Request Payload"
    json response "ğŸ“¥ Response Data"
    string model "ğŸ·ï¸ Model Name"
    timestamp created_at
    timestamp updated_at
  }
```

### ğŸ“‹ InformaÃ§Ãµes Relevantes do Modelo de Dados

#### ğŸ›ï¸ Entidades Principais e Seus PropÃ³sitos

**ğŸ”Œ Integration (IntegraÃ§Ãµes)**
- **PropÃ³sito**: Representa cada API de instituiÃ§Ã£o de ensino (Kroton, EstÃ¡cio, etc.)
- **Campos CrÃ­ticos**:
  - `name`: Nome da instituiÃ§Ã£o para identificaÃ§Ã£o
  - `type`: Tipo de integraÃ§Ã£o (REST, SOAP, GraphQL)
  - `key`: Chave de identificaÃ§Ã£o Ãºnica da API
  - `interval`: Intervalo em minutos para sincronizaÃ§Ã£o via cron

**ğŸ¯ IntegrationFilter (Filtros de IntegraÃ§Ã£o)**
- **PropÃ³sito**: Define regras de negÃ³cio especÃ­ficas por instituiÃ§Ã£o
- **Campos CrÃ­ticos**:
  - `filter`: JSON contendo regras (ex: cursos aceitos, regiÃµes, faixa etÃ¡ria)
  - `type`: Tipo de filtro (course, region, demographic, etc.)
  - `enabled`: Flag para ativar/desativar filtro dinamicamente

**ğŸ“¦ Subscription (InscriÃ§Ãµes)**
- **PropÃ³sito**: Representa cada inscriÃ§Ã£o de aluno a ser processada
- **Campos CrÃ­ticos**:
  - `order_id`: ID do pedido no sistema origem (Quero Bolsa, etc.)
  - `origin`: Marketplace de origem (quero_bolsa, ead_com, etc.)
  - `cpf`: CPF do aluno para identificaÃ§Ã£o Ãºnica
  - `payload`: Dados completos do aluno em formato JSON
  - `status`: Estado atual (pending, sent, confirmed, failed)
  - Timestamps para controle de fluxo temporal

**ğŸ” IntegrationToken (Tokens de AutenticaÃ§Ã£o)**
- **PropÃ³sito**: Gerencia tokens de acesso Ã s APIs das instituiÃ§Ãµes
- **Campos CrÃ­ticos**:
  - `key`: Tipo de token (access_token, api_key, bearer, etc.)
  - `value`: Valor do token criptografado
  - `valid_until`: Data de expiraÃ§Ã£o para renovaÃ§Ã£o automÃ¡tica

**ğŸ“ SubscriptionEvent (Log de Eventos)**
- **PropÃ³sito**: Auditoria completa de todas as operaÃ§Ãµes
- **Campos CrÃ­ticos**:
  - `status`: Resultado da operaÃ§Ã£o (success, error, retry)
  - `operation_name`: Nome da operaÃ§Ã£o (register_sync, checker, cron)
  - `error_message`: Detalhes de erro para debugging
  - `request`/`response`: Payloads completos para anÃ¡lise

#### ğŸ”„ Relacionamentos e Fluxo de Dados

ğŸ—ï¸ Hierarquia de DependÃªncias

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
graph TD
    subgraph "ğŸ›ï¸ ConfiguraÃ§Ã£o de InstituiÃ§Ãµes"
        INT["ğŸ”Œ Integration<br/>ğŸ“‹ InstituiÃ§Ã£o de Ensino<br/>(Kroton, EstÃ¡cio, etc.)"]
        
        subgraph "ğŸ¯ Regras de NegÃ³cio"
            FILTER1["ğŸ§° IntegrationFilter<br/>ğŸ“š Filtro de Cursos"]
            FILTER2["ğŸŒ IntegrationFilter<br/>ğŸ“ Filtro Regional"]
            FILTER3["ğŸ‘¥ IntegrationFilter<br/>ğŸ¯ Filtro DemogrÃ¡fico"]
        end
        
        subgraph "ğŸ” AutenticaÃ§Ã£o"
            TOKEN1["ğŸ« IntegrationToken<br/>ğŸ”‘ Access Token"]
            TOKEN2["ğŸ—ï¸ IntegrationToken<br/>ğŸ” API Key"]
            TOKEN3["ğŸŸï¸ IntegrationToken<br/>â° Refresh Token"]
        end
    end
    
    subgraph "ğŸ“¦ Processamento de InscriÃ§Ãµes"
        SUB1["ğŸ“ Subscription<br/>ğŸ‘¤ Aluno Quero Bolsa"]
        SUB2["ğŸ“ Subscription<br/>ğŸ‘¤ Aluno EAD.com"]
        SUB3["ğŸ“ Subscription<br/>ğŸ‘¤ Aluno Guia Carreira"]
        
        subgraph "ğŸ“Š Auditoria e Logs"
            EVENT1["ğŸ“‹ SubscriptionEvent<br/>âœ… Envio Sucesso"]
            EVENT2["ğŸ“‹ SubscriptionEvent<br/>ğŸ”„ Tentativa Retry"]
            EVENT3["ğŸ“‹ SubscriptionEvent<br/>âŒ Erro Processamento"]
            EVENT4["ğŸ“‹ SubscriptionEvent<br/>ğŸ” VerificaÃ§Ã£o Status"]
        end
    end
    
    %% Relacionamentos principais
    INT -->|"has_many<br/>ğŸ¯ define regras"| FILTER1
    INT -->|"has_many<br/>ğŸ¯ define regras"| FILTER2
    INT -->|"has_many<br/>ğŸ¯ define regras"| FILTER3
    
    INT -->|"has_many<br/>ğŸ” autentica"| TOKEN1
    INT -->|"has_many<br/>ğŸ” autentica"| TOKEN2
    INT -->|"has_many<br/>ğŸ” autentica"| TOKEN3
    
    INT -->|"has_many<br/>ğŸ“¦ processa"| SUB1
    INT -->|"has_many<br/>ğŸ“¦ processa"| SUB2
    INT -->|"has_many<br/>ğŸ“¦ processa"| SUB3
    
    FILTER1 -->|"has_many<br/>âœ… aplica filtro"| SUB1
    FILTER2 -->|"has_many<br/>âœ… aplica filtro"| SUB2
    FILTER3 -->|"has_many<br/>âœ… aplica filtro"| SUB3
    
    SUB1 -->|"has_many<br/>ğŸ“ registra eventos"| EVENT1
    SUB1 -->|"has_many<br/>ğŸ“ registra eventos"| EVENT2
    SUB2 -->|"has_many<br/>ğŸ“ registra eventos"| EVENT3
    SUB3 -->|"has_many<br/>ğŸ“ registra eventos"| EVENT4
    
    classDef integration fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef filter fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef token fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef subscription fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    classDef event fill:#FCE4EC,stroke:#E91E63,color:#2C3E50
    
    class INT integration
    class FILTER1,FILTER2,FILTER3 filter
    class TOKEN1,TOKEN2,TOKEN3 token
    class SUB1,SUB2,SUB3 subscription
    class EVENT1,EVENT2,EVENT3,EVENT4 event
```

**Fluxo de Processamento:**
1. **Integration** define a instituiÃ§Ã£o de destino
2. **IntegrationFilter** determina quais alunos sÃ£o elegÃ­veis
3. **Subscription** armazena dados do aluno para processamento
4. **IntegrationToken** fornece autenticaÃ§Ã£o para API calls
5. **SubscriptionEvent** registra cada tentativa e resultado

#### ğŸ“Š Estados e TransiÃ§Ãµes

**Status da Subscription:**
- `pending`: Aguardando processamento
- `filtered`: NÃ£o passou nos filtros da instituiÃ§Ã£o
- `sent`: Enviado para API da instituiÃ§Ã£o
- `confirmed`: Confirmado pela instituiÃ§Ã£o
- `failed`: Falha no processamento
- `retry`: Agendado para nova tentativa

**Tipos de SubscriptionEvent:**
- `register_sync`: Processamento individual em tempo real
- `register_cron`: Processamento em lote via cron
- `checker`: VerificaÃ§Ã£o de status na instituiÃ§Ã£o
- `token_refresh`: RenovaÃ§Ã£o de tokens
- `retry_attempt`: Tentativa de reenvio

#### ğŸ›¡ï¸ ConsideraÃ§Ãµes de SeguranÃ§a e Performance

**SeguranÃ§a:**
- CPF deve ser hasheado/criptografado em produÃ§Ã£o
- Tokens devem ser armazenados com criptografia
- Payload pode conter dados sensÃ­veis - considerar anonimizaÃ§Ã£o

**Performance:**
- Indexar `order_id`, `cpf`, `status` para consultas rÃ¡pidas
- Particionamento de `SubscriptionEvent` por data
- Cache de `IntegrationFilter` para reduzir consultas
- Cleanup automÃ¡tico de eventos antigos

**Monitoramento:**
- MÃ©tricas por status de subscription
- Alertas para falhas em integraÃ§Ãµes especÃ­ficas
- Dashboard de performance por instituiÃ§Ã£o

## Fluxos do Projeto

### ğŸ—ï¸ VisÃ£o Geral do Sistema (Overview)

ğŸ—ï¸ Diagrama de VisÃ£o Geral do Sistema

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart TD
    subgraph "ğŸŒ Marketplaces"
        QB["ğŸ“ Quero Bolsa"]
        EAD["ğŸ“š EAD.com"]
        GC["ğŸ—ï¸ Guia da Carreira"]
        MV["ğŸ¯ Mundo Vestibular"]
    end
    
    subgraph "âš™ï¸ Anubis Service"
        ANUBIS["ğŸ”„ Anubis<br/>Orchestrator"]
        QUEUE["ğŸ“¥ Message Queue"]
        PROC["âš¡ Processor"]
        LOG["ğŸ“ Event Logger"]
    end
    
    subgraph "ğŸ›ï¸ Institution APIs"
        KROTON["ğŸ¢ Kroton API"]
        ESTACIO["ğŸ« EstÃ¡cio API"]
        OTHER["ğŸ¤ Other APIs"]
    end
    
    subgraph "ğŸ’¾ Storage"
        DB["ğŸ—„ï¸ PostgreSQL"]
        KAFKA["ğŸ“¨ Kafka"]
    end
    
    QB --> ANUBIS
    EAD --> ANUBIS
    GC --> ANUBIS
    MV --> ANUBIS
    
    ANUBIS --> QUEUE
    QUEUE --> PROC
    PROC --> LOG
    
    PROC --> KROTON
    PROC --> ESTACIO
    PROC --> OTHER
    
    LOG --> DB
    ANUBIS --> KAFKA
    
    classDef marketplace fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef anubis fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef institution fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef storage fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    
    class QB,EAD,GC,MV marketplace
    class ANUBIS,QUEUE,PROC,LOG anubis
    class KROTON,ESTACIO,OTHER institution
    class DB,KAFKA storage
```

**ğŸ“‹ ExplicaÃ§Ã£o da VisÃ£o Geral:**

O Anubis atua como um **orquestrador central** que recebe dados de alunos pagantes de mÃºltiplos marketplaces educacionais e os distribui para as APIs das instituiÃ§Ãµes de ensino superior. O fluxo Ã© unidirecional e assÃ­ncrono:

- **Entrada de Dados**: Quero Bolsa, EAD.com, Guia da Carreira e Mundo Vestibular enviam informaÃ§Ãµes de inscriÃ§Ãµes
- **Processamento**: O Anubis valida, transforma e enfileira os dados para processamento
- **DistribuiÃ§Ã£o**: Os dados sÃ£o enviados para APIs de instituiÃ§Ãµes como Kroton, EstÃ¡cio e outras
- **PersistÃªncia**: PostgreSQL armazena os dados estruturados e logs, enquanto Kafka gerencia mensagens assÃ­ncronas
- **Monitoramento**: Cada operaÃ§Ã£o Ã© logada para auditoria e debugging

### ğŸ”§ Arquitetura de ServiÃ§os

ğŸ”§ Diagrama da Arquitetura de ServiÃ§os

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart LR
    subgraph "ğŸŒ Marketplace Events"
        QB_EVENT["ğŸ“ Quero Bolsa Events"]
        EAD_EVENT["ğŸ“š EAD.com Events"]
        GC_EVENT["ï¿½ï¸ Guia Carreira Events"]
        MV_EVENT["ğŸ¯ Mundo Vestibular Events"]
    end
    
    subgraph "ğŸ”„ Anubis Core"
        REGISTER["ğŸ“‹ Register Sync"]
        SCHEDULER["â° Scheduler"]
        CHECKER["ğŸ” Checker"]
        RETRY["ğŸ”„ Retry Logic"]
    end
    
    subgraph "ğŸ¯ Integration Layer"
        FILTER["ğŸ§° Filters"]
        TOKEN["ğŸ” Token Manager"]
        PAYLOAD["ğŸ“„ Payload Builder"]
    end
    
    subgraph "ğŸ“¤ Output Services"
        API_CLIENT["ğŸŒ API Client"]
        EVENT_LOG["ğŸ“ Event Logger"]
    end
    
    QB_EVENT --> REGISTER
    EAD_EVENT --> REGISTER
    GC_EVENT --> REGISTER
    MV_EVENT --> REGISTER
    
    REGISTER --> SCHEDULER
    SCHEDULER --> CHECKER
    CHECKER --> RETRY
    
    REGISTER --> FILTER
    FILTER --> TOKEN
    TOKEN --> PAYLOAD
    
    PAYLOAD --> API_CLIENT
    API_CLIENT --> EVENT_LOG
    CHECKER --> EVENT_LOG
    
    classDef source fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef core fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef integration fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef output fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    
    class QB_EVENT,EAD_EVENT,GC_EVENT,MV_EVENT source
    class REGISTER,SCHEDULER,CHECKER,RETRY core
    class FILTER,TOKEN,PAYLOAD integration
    class API_CLIENT,EVENT_LOG output
```

**âš™ï¸ ExplicaÃ§Ã£o da Arquitetura de ServiÃ§os:**

Esta arquitetura modular divide o Anubis em **componentes especializados** que trabalham em conjunto:

- **Eventos de Marketplaces**: Quero Bolsa, EAD.com, Guia da Carreira e Mundo Vestibular enviam eventos de inscriÃ§Ãµes de alunos pagantes
- **NÃºcleo de Processamento**: 
  - **Register Sync**: Processa inscriÃ§Ãµes em tempo real
  - **Scheduler**: Agenda tarefas e verificaÃ§Ãµes periÃ³dicas
  - **Checker**: Monitora status das integraÃ§Ãµes
  - **Retry Logic**: Gerencia reenvios automÃ¡ticos em caso de falha
- **Camada de IntegraÃ§Ã£o**:
  - **Filters**: Aplicam regras de negÃ³cio especÃ­ficas por instituiÃ§Ã£o
  - **Token Manager**: Gerencia autenticaÃ§Ã£o e tokens de acesso
  - **Payload Builder**: ConstrÃ³i dados no formato esperado por cada API
- **ServiÃ§os de SaÃ­da**:
  - **API Client**: Comunica com APIs externas das instituiÃ§Ãµes
  - **Event Logger**: Registra todos os eventos para auditoria

#### ğŸ“‹ Fluxo Register Sync

ğŸ“‹ Diagrama do Fluxo Register Sync

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart TD
    START["ğŸš€ Start Process"]
    
    subgraph "ğŸ“¥ Data Collection"
        RECEIVE["ğŸ“¨ Receive Order Event"]
        VALIDATE["âœ… Validate Data"]
        EXTRACT["ğŸ” Extract Student Info"]
    end
    
    subgraph "ğŸ¯ Integration Matching"
        FIND_INT["ğŸ” Find Integrations"]
        APPLY_FILTER["ğŸ§° Apply Filters"]
        CHECK_RULES["ğŸ“‹ Check Rules"]
    end
    
    subgraph "ğŸ“„ Payload Processing"
        BUILD_PAYLOAD["ğŸ”§ Build Payload"]
        ADD_TOKEN["ğŸ” Add Auth Token"]
        VALIDATE_PAYLOAD["âœ… Validate Payload"]
    end
    
    subgraph "ğŸ“¤ Delivery"
        SEND_API["ğŸŒ Send to Institution API"]
        LOG_EVENT["ğŸ“ Log Event"]
        SCHEDULE_CHECK["â° Schedule Check"]
    end
    
    SUCCESS["âœ… Success"]
    ERROR["âŒ Error"]
    RETRY["ğŸ”„ Schedule Retry"]
    
    START --> RECEIVE
    RECEIVE --> VALIDATE
    VALIDATE --> EXTRACT
    
    EXTRACT --> FIND_INT
    FIND_INT --> APPLY_FILTER
    APPLY_FILTER --> CHECK_RULES
    
    CHECK_RULES --> BUILD_PAYLOAD
    BUILD_PAYLOAD --> ADD_TOKEN
    ADD_TOKEN --> VALIDATE_PAYLOAD
    
    VALIDATE_PAYLOAD --> SEND_API
    SEND_API --> LOG_EVENT
    LOG_EVENT --> SCHEDULE_CHECK
    
    SCHEDULE_CHECK --> SUCCESS
    
    VALIDATE -->|âŒ Invalid| ERROR
    CHECK_RULES -->|âŒ No Match| ERROR
    SEND_API -->|âŒ Failed| ERROR
    
    ERROR --> RETRY
    RETRY --> FIND_INT
    
    classDef start fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef process fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef decision fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef endNode fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    
    class START start
    class RECEIVE,VALIDATE,EXTRACT,FIND_INT,APPLY_FILTER,CHECK_RULES,BUILD_PAYLOAD,ADD_TOKEN,VALIDATE_PAYLOAD,SEND_API,LOG_EVENT,SCHEDULE_CHECK process
    class SUCCESS,ERROR,RETRY endNode
```

**ğŸ”„ ExplicaÃ§Ã£o do Register Sync:**

O **Register Sync** Ã© o processo principal de sincronizaÃ§Ã£o em tempo real que processa cada inscriÃ§Ã£o individualmente:

1. **Coleta de Dados**:
   - Recebe eventos de inscriÃ§Ã£o dos marketplaces
   - Valida integridade e formato dos dados
   - Extrai informaÃ§Ãµes do aluno (CPF, dados pessoais, curso)

2. **Matching de IntegraÃ§Ã£o**:
   - Busca integraÃ§Ãµes ativas para a instituiÃ§Ã£o
   - Aplica filtros especÃ­ficos (curso, regiÃ£o, perfil do aluno)
   - Verifica regras de negÃ³cio antes do envio

3. **PreparaÃ§Ã£o do Payload**:
   - ConstrÃ³i payload no formato esperado pela API da instituiÃ§Ã£o
   - Adiciona tokens de autenticaÃ§Ã£o vÃ¡lidos
   - Valida estrutura final do payload

4. **Entrega e Logging**:
   - Envia dados para API da instituiÃ§Ã£o
   - Registra evento com status de sucesso/falha
   - Agenda verificaÃ§Ã£o posterior do status de processamento

5. **Tratamento de Erros**:
   - Em caso de falha, programa retry automÃ¡tico
   - MantÃ©m contador de tentativas
   - Escalona para intervenÃ§Ã£o manual apÃ³s limite de tentativas

#### â° Fluxo Register Cron

â° Diagrama do Fluxo Register Cron

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart TD
    CRON_START["â° Cron Job Started"]
    
    subgraph "ğŸ” Discovery Phase"
        FETCH_INTEGRATIONS["ğŸ“‹ Fetch Active Integrations"]
        CHECK_INTERVAL["â±ï¸ Check Sync Intervals"]
        FILTER_DUE["ğŸ¯ Filter Due Syncs"]
    end
    
    subgraph "ğŸ“Š Data Processing"
        FETCH_ORDERS["ğŸ“¦ Fetch Pending Orders"]
        GROUP_BY_INT["ğŸ—‚ï¸ Group by Integration"]
        PREPARE_BATCH["ğŸ“‹ Prepare Batch"]
    end
    
    subgraph "âš¡ Batch Execution"
        PROCESS_BATCH["âš¡ Process Batch"]
        APPLY_FILTERS["ğŸ§° Apply Integration Filters"]
        BUILD_PAYLOADS["ğŸ“„ Build Payloads"]
    end
    
    subgraph "ğŸ“¤ Delivery & Logging"
        SEND_BATCH["ğŸŒ Send Batch to APIs"]
        LOG_RESULTS["ğŸ“ Log Results"]
        UPDATE_STATUS["ğŸ“Š Update Status"]
    end
    
    COMPLETE["âœ… Cron Complete"]
    ERROR_HANDLER["âŒ Error Handler"]
    SCHEDULE_RETRY["ğŸ”„ Schedule Retry"]
    
    CRON_START --> FETCH_INTEGRATIONS
    FETCH_INTEGRATIONS --> CHECK_INTERVAL
    CHECK_INTERVAL --> FILTER_DUE
    
    FILTER_DUE --> FETCH_ORDERS
    FETCH_ORDERS --> GROUP_BY_INT
    GROUP_BY_INT --> PREPARE_BATCH
    
    PREPARE_BATCH --> PROCESS_BATCH
    PROCESS_BATCH --> APPLY_FILTERS
    APPLY_FILTERS --> BUILD_PAYLOADS
    
    BUILD_PAYLOADS --> SEND_BATCH
    SEND_BATCH --> LOG_RESULTS
    LOG_RESULTS --> UPDATE_STATUS
    
    UPDATE_STATUS --> COMPLETE
    
    PROCESS_BATCH -->|âŒ Error| ERROR_HANDLER
    SEND_BATCH -->|âŒ Failed| ERROR_HANDLER
    ERROR_HANDLER --> SCHEDULE_RETRY
    SCHEDULE_RETRY --> PROCESS_BATCH
    
    classDef cron fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef discovery fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef processing fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef delivery fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    classDef endNode fill:#FCE4EC,stroke:#E91E63,color:#2C3E50
    
    class CRON_START cron
    class FETCH_INTEGRATIONS,CHECK_INTERVAL,FILTER_DUE discovery
    class FETCH_ORDERS,GROUP_BY_INT,PREPARE_BATCH,PROCESS_BATCH,APPLY_FILTERS,BUILD_PAYLOADS processing
    class SEND_BATCH,LOG_RESULTS,UPDATE_STATUS delivery
    class COMPLETE,ERROR_HANDLER,SCHEDULE_RETRY endNode
```

**â° ExplicaÃ§Ã£o do Register Cron:**

O **Register Cron** Ã© o processo batch que executa periodicamente para processar volumes maiores de dados:

1. **Fase de Descoberta**:
   - Executa em intervalos programados (ex: a cada hora)
   - Busca todas as integraÃ§Ãµes ativas no sistema
   - Filtra integraÃ§Ãµes que estÃ£o no tempo de sincronizaÃ§Ã£o
   - Identifica quais precisam de processamento batch

2. **Processamento de Dados**:
   - Busca pedidos pendentes no perÃ­odo
   - Agrupa por integraÃ§Ã£o para otimizar processamento
   - Prepara lotes (batches) para envio em massa

3. **ExecuÃ§Ã£o em Lote**:
   - Processa mÃºltiplas inscriÃ§Ãµes simultaneamente
   - Aplica filtros de integraÃ§Ã£o em massa
   - ConstrÃ³i payloads otimizados para envio batch

4. **Entrega e Monitoramento**:
   - Envia lotes para APIs das instituiÃ§Ãµes
   - Registra resultados de cada lote processado
   - Atualiza status de todas as inscriÃ§Ãµes processadas

5. **RecuperaÃ§Ã£o de Erros**:
   - Identifica lotes que falharam
   - Agenda reprocessamento automÃ¡tico
   - MantÃ©m mÃ©tricas de performance e taxa de sucesso

**ğŸ’¡ DiferenÃ§a entre Sync e Cron:**
- **Sync**: Processa inscriÃ§Ãµes individuais em tempo real
- **Cron**: Processa lotes de inscriÃ§Ãµes em intervalos programados

#### ğŸ” Fluxo Checker

ğŸ” Diagrama do Fluxo Checker

```mermaid
%%{init: {
  'theme':'base',
  'themeVariables': {
    'primaryColor':'#E8F4FD',
    'primaryBorderColor':'#4A90E2',
    'primaryTextColor':'#2C3E50',
    'secondaryColor':'#F0F8E8',
    'tertiaryColor':'#FDF2E8',
    'quaternaryColor':'#F8E8F8',
    'lineColor':'#5D6D7E',
    'fontFamily':'Inter,Segoe UI,Arial'
  }
}}%%
flowchart TD
    CHECKER_START["ğŸ” Checker Started"]
    
    subgraph "ğŸ“Š Status Monitoring"
        FETCH_PENDING["ğŸ“‹ Fetch Pending Subscriptions"]
        CHECK_SCHEDULE["â° Check Scheduled Time"]
        FILTER_READY["ğŸ¯ Filter Ready to Check"]
    end
    
    subgraph "ğŸŒ API Verification"
        CALL_STATUS_API["ğŸ“ Call Institution Status API"]
        PARSE_RESPONSE["ğŸ“„ Parse Response"]
        EXTRACT_STATUS["ğŸ” Extract Status"]
    end
    
    subgraph "ğŸ”„ Status Processing"
        COMPARE_STATUS["âš–ï¸ Compare with Current"]
        UPDATE_SUBSCRIPTION["ğŸ“Š Update Subscription"]
        DETERMINE_ACTION["ğŸ¤” Determine Next Action"]
    end
    
    subgraph "ğŸ“ Event Logging"
        LOG_CHECK["ğŸ“ Log Check Event"]
        UPDATE_TIMESTAMP["â° Update Check Timestamp"]
        STORE_RESPONSE["ğŸ’¾ Store API Response"]
    end
    
    subgraph "ğŸ¯ Action Decision"
        SUCCESS["âœ… Processing Complete"]
        PENDING["â³ Still Pending"]
        FAILED["âŒ Processing Failed"]
        RETRY_NEEDED["ğŸ”„ Retry Required"]
    end
    
    SCHEDULE_NEXT["â° Schedule Next Check"]
    TRIGGER_RETRY["ğŸ”„ Trigger Retry Process"]
    COMPLETE["âœ… Check Complete"]
    
    CHECKER_START --> FETCH_PENDING
    FETCH_PENDING --> CHECK_SCHEDULE
    CHECK_SCHEDULE --> FILTER_READY
    
    FILTER_READY --> CALL_STATUS_API
    CALL_STATUS_API --> PARSE_RESPONSE
    PARSE_RESPONSE --> EXTRACT_STATUS
    
    EXTRACT_STATUS --> COMPARE_STATUS
    COMPARE_STATUS --> UPDATE_SUBSCRIPTION
    UPDATE_SUBSCRIPTION --> DETERMINE_ACTION
    
    DETERMINE_ACTION --> LOG_CHECK
    LOG_CHECK --> UPDATE_TIMESTAMP
    UPDATE_TIMESTAMP --> STORE_RESPONSE
    
    STORE_RESPONSE --> SUCCESS
    STORE_RESPONSE --> PENDING
    STORE_RESPONSE --> FAILED
    STORE_RESPONSE --> RETRY_NEEDED
    
    SUCCESS --> COMPLETE
    PENDING --> SCHEDULE_NEXT
    FAILED --> COMPLETE
    RETRY_NEEDED --> TRIGGER_RETRY
    
    SCHEDULE_NEXT --> COMPLETE
    TRIGGER_RETRY --> COMPLETE
    
    CALL_STATUS_API -->|âŒ API Error| FAILED
    
    classDef start fill:#E8F4FD,stroke:#4A90E2,color:#2C3E50
    classDef monitoring fill:#F0F8E8,stroke:#7CB342,color:#2C3E50
    classDef api fill:#FDF2E8,stroke:#FF9800,color:#2C3E50
    classDef processing fill:#F8E8F8,stroke:#9C27B0,color:#2C3E50
    classDef decision fill:#FCE4EC,stroke:#E91E63,color:#2C3E50
    classDef endNode fill:#E1F5FE,stroke:#00BCD4,color:#2C3E50
    
    class CHECKER_START start
    class FETCH_PENDING,CHECK_SCHEDULE,FILTER_READY monitoring
    class CALL_STATUS_API,PARSE_RESPONSE,EXTRACT_STATUS api
    class COMPARE_STATUS,UPDATE_SUBSCRIPTION,DETERMINE_ACTION,LOG_CHECK,UPDATE_TIMESTAMP,STORE_RESPONSE processing
    class SUCCESS,PENDING,FAILED,RETRY_NEEDED decision
    class SCHEDULE_NEXT,TRIGGER_RETRY,COMPLETE endNode
```

**ğŸ” ExplicaÃ§Ã£o do Fluxo Checker:**

O **Checker** Ã© o componente responsÃ¡vel por **monitorar o status de processamento** das inscriÃ§Ãµes nas instituiÃ§Ãµes:

1. **Monitoramento de Status**:
   - Executa periodicamente para verificar inscriÃ§Ãµes pendentes
   - Identifica inscriÃ§Ãµes que precisam de verificaÃ§Ã£o de status
   - Filtra apenas aquelas que atingiram o tempo de verificaÃ§Ã£o programado

2. **VerificaÃ§Ã£o via API**:
   - Chama APIs de status das instituiÃ§Ãµes para consultar andamento
   - Faz parsing das respostas que podem ter formatos diferentes por instituiÃ§Ã£o
   - Extrai informaÃ§Ãµes relevantes sobre o status atual da inscriÃ§Ã£o

3. **Processamento de Status**:
   - Compara status atual com status anterior armazenado
   - Atualiza informaÃ§Ãµes da inscriÃ§Ã£o no banco de dados
   - Determina prÃ³xima aÃ§Ã£o baseada no novo status

4. **Logging de Eventos**:
   - Registra cada verificaÃ§Ã£o realizada
   - Atualiza timestamp da Ãºltima verificaÃ§Ã£o
   - Armazena resposta completa da API para auditoria

5. **DecisÃµes de Fluxo**:
   - **Sucesso**: InscriÃ§Ã£o foi processada com sucesso pela instituiÃ§Ã£o
   - **Pendente**: Ainda em processamento, agenda prÃ³xima verificaÃ§Ã£o
   - **Falha**: Processamento falhou na instituiÃ§Ã£o, marca como erro
   - **Retry**: Problema temporÃ¡rio, agenda nova tentativa de envio

**ğŸ¯ Objetivo do Checker:**
Garantir que todas as inscriÃ§Ãµes enviadas sejam devidamente processadas pelas instituiÃ§Ãµes, fornecendo visibilidade completa do pipeline de integraÃ§Ã£o e permitindo intervenÃ§Ãµes quando necessÃ¡rio.

## ğŸ“‹ Requisitos Funcionais

### ğŸ”„ Processamento de InscriÃ§Ãµes
- **RF001**: O sistema deve receber inscriÃ§Ãµes de alunos pagantes dos marketplaces (Quero Bolsa, EAD.com, Guia da Carreira, Mundo Vestibular)
- **RF002**: O sistema deve validar dados obrigatÃ³rios antes do processamento (CPF, dados pessoais, curso)
- **RF003**: O sistema deve aplicar filtros especÃ­ficos por instituiÃ§Ã£o antes do envio
- **RF004**: O sistema deve construir payloads no formato esperado por cada API de instituiÃ§Ã£o
- **RF005**: O sistema deve gerenciar tokens de autenticaÃ§Ã£o automaticamente

### ğŸ“¤ IntegraÃ§Ã£o com APIs
- **RF006**: O sistema deve enviar dados para APIs de instituiÃ§Ãµes de ensino superior
- **RF007**: O sistema deve implementar retry automÃ¡tico para falhas temporÃ¡rias (mÃ¡ximo 3 tentativas)
- **RF008**: O sistema deve verificar status de processamento nas instituiÃ§Ãµes periodicamente
- **RF009**: O sistema deve processar respostas em diferentes formatos (JSON, XML, etc.)

### ğŸ“Š Monitoramento e Auditoria
- **RF010**: O sistema deve registrar logs estruturados de todas as operaÃ§Ãµes
- **RF011**: O sistema deve manter histÃ³rico completo de tentativas e respostas
- **RF012**: O sistema deve gerar mÃ©tricas de performance por instituiÃ§Ã£o
- **RF013**: O sistema deve alertar sobre falhas crÃ­ticas e integraÃ§Ãµes inativas

## ğŸ›¡ï¸ Requisitos NÃ£o-Funcionais

### ğŸš€ Performance
- **RNF001**: O sistema deve processar atÃ© 10.000 inscriÃ§Ãµes por hora
- **RNF002**: Tempo de resposta mÃ¡ximo de 5 segundos para processamento individual
- **RNF003**: Processamento em lote deve completar em atÃ© 30 minutos
- **RNF004**: APIs de instituiÃ§Ãµes devem ter timeout de 30 segundos

### ğŸ”’ SeguranÃ§a
- **RNF005**: CPFs devem ser armazenados com hash SHA-256
- **RNF006**: Tokens de API devem ser criptografados em repouso
- **RNF007**: Logs nÃ£o devem expor dados sensÃ­veis dos alunos
- **RNF008**: ComunicaÃ§Ã£o com APIs deve usar HTTPS/TLS 1.2+

### ğŸ“ˆ Escalabilidade
- **RNF009**: Sistema deve suportar crescimento de 50% ao ano no volume
- **RNF010**: Banco de dados deve suportar particionamento por data
- **RNF011**: Sistema deve funcionar em arquitetura de microserviÃ§os
- **RNF012**: Deve permitir adiÃ§Ã£o de novas instituiÃ§Ãµes sem impacto

### ğŸ”§ Confiabilidade
- **RNF013**: Disponibilidade mÃ­nima de 99.5% (excluindo manutenÃ§Ãµes)
- **RNF014**: Backup automÃ¡tico diÃ¡rio dos dados crÃ­ticos
- **RNF015**: RecuperaÃ§Ã£o em caso de falha em atÃ© 1 hora
- **RNF016**: RetenÃ§Ã£o de logs por no mÃ­nimo 6 meses

## ğŸ¯ CritÃ©rios de AceitaÃ§Ã£o

### âœ… CenÃ¡rios de Sucesso
1. **Processamento Normal**: InscriÃ§Ã£o vÃ¡lida Ã© enviada e confirmada pela instituiÃ§Ã£o
2. **AplicaÃ§Ã£o de Filtros**: InscriÃ§Ã£o Ã© filtrada corretamente baseada nas regras
3. **Retry AutomÃ¡tico**: Falha temporÃ¡ria Ã© recuperada automaticamente
4. **Monitoramento**: Dashboards mostram mÃ©tricas em tempo real

### âŒ CenÃ¡rios de Erro
1. **Dados InvÃ¡lidos**: Sistema rejeita e loga inscriÃ§Ãµes com dados inconsistentes
2. **API IndisponÃ­vel**: Sistema agenda retry e notifica equipe de operaÃ§Ãµes
3. **Token Expirado**: Sistema renova automaticamente ou alerta para renovaÃ§Ã£o manual
4. **Limite de Tentativas**: ApÃ³s 3 falhas, marca para intervenÃ§Ã£o manual

## ğŸš« ExclusÃµes do Escopo

- **NÃ£o incluÃ­do**: Envio de leads do Quero CaptaÃ§Ã£o
- **NÃ£o incluÃ­do**: Alunos pagantes de outros produtos Qeevo
- **NÃ£o incluÃ­do**: Interface para reenvio manual de falhas
- **NÃ£o incluÃ­do**: Agendamento customizado de envios
- **NÃ£o incluÃ­do**: RelatÃ³rios financeiros ou de cobranÃ§a

## ğŸ› ï¸ EspecificaÃ§Ãµes TÃ©cnicas Rails

### ğŸ“¦ Stack TecnolÃ³gico
- **Framework**: Rails 8.0.3
- **Ruby Version**: 3.4.5
- **Database**: PostgreSQL 17
- **Job Processing**: Solid Queue (produÃ§Ã£o), Async (desenvolvimento)
- **Cache**: Solid Cache
- **WebSocket**: Solid Cable
- **Deployment**: Kamal + Docker

### ğŸ—ï¸ Arquitetura de Componentes Rails

#### ğŸ“‹ Models & Associations
```ruby
# app/models/integration.rb
class Integration < ApplicationRecord
  has_many :integration_filters, dependent: :destroy
  has_many :integration_tokens, dependent: :destroy
  has_many :subscriptions, dependent: :restrict_with_error
  
  validates :name, presence: true, uniqueness: true
  validates :type, inclusion: { in: %w[rest soap graphql] }
  validates :interval, numericality: { greater_than: 0 }
  
  scope :active, -> { where(enabled: true) }
  scope :due_for_sync, -> { where('last_sync_at < ?', interval.minutes.ago) }
end

# app/models/subscription.rb
class Subscription < ApplicationRecord
  include AASM
  
  belongs_to :integration
  belongs_to :integration_filter
  has_many :subscription_events, dependent: :destroy
  
  validates :cpf, presence: true, format: { with: /\A\d{11}\z/ }
  validates :order_id, presence: true, uniqueness: true
  
  aasm column: :status do
    state :pending, initial: true
    state :filtered, :sent, :confirmed, :failed, :retry
    
    event :filter_out do
      transitions from: :pending, to: :filtered
    end
    
    event :send_to_institution do
      transitions from: [:pending, :retry], to: :sent
    end
    
    event :confirm_processing do
      transitions from: :sent, to: :confirmed
    end
    
    event :mark_failed do
      transitions from: [:pending, :sent, :retry], to: :failed
    end
    
    event :schedule_retry do
      transitions from: [:sent, :failed], to: :retry
    end
  end
end
```

#### ğŸ”„ Jobs & Background Processing
```ruby
# app/jobs/register_sync_job.rb
class RegisterSyncJob < ApplicationJob
  queue_as :high_priority
  retry_on StandardError, wait: :exponentially_longer, attempts: 3
  
  def perform(subscription_id)
    subscription = Subscription.find(subscription_id)
    RegisterSyncService.new(subscription).call
  end
end

# app/jobs/register_cron_job.rb
class RegisterCronJob < ApplicationJob
  queue_as :default
  
  def perform
    Integration.active.due_for_sync.find_each do |integration|
      RegisterBatchService.new(integration).call
    end
  end
end

# app/jobs/checker_job.rb
class CheckerJob < ApplicationJob
  queue_as :low_priority
  
  def perform
    subscriptions = Subscription.sent
                              .where('checked_at < ? OR checked_at IS NULL', 1.hour.ago)
    
    subscriptions.find_each do |subscription|
      CheckerService.new(subscription).call
    end
  end
end
```

#### ğŸ¯ Services & Business Logic
```ruby
# app/services/register_sync_service.rb
class RegisterSyncService < ApplicationService
  def initialize(subscription)
    @subscription = subscription
    @integration = subscription.integration
  end
  
  def call
    return filter_subscription unless passes_filters?
    
    payload = build_payload
    response = send_to_api(payload)
    
    if response.success?
      @subscription.send_to_institution!
      schedule_status_check
    else
      handle_failure(response)
    end
    
    log_event(response)
  end
  
  private
  
  def passes_filters?
    @subscription.integration_filter.apply(@subscription)
  end
  
  def build_payload
    PayloadBuilder.new(@subscription, @integration).build
  end
  
  def send_to_api(payload)
    ApiClient.new(@integration).post(payload)
  end
end

# app/services/application_service.rb
class ApplicationService
  def self.call(*args, &block)
    new(*args, &block).call
  end
end
```

#### ğŸ”Œ API Integration
```ruby
# app/lib/api_client.rb
class ApiClient
  def initialize(integration)
    @integration = integration
    @base_url = integration.base_url
    @timeout = 30.seconds
  end
  
  def post(payload)
    connection.post do |req|
      req.url endpoint_path
      req.headers = headers
      req.body = payload.to_json
    end
  rescue Faraday::TimeoutError => e
    ApiResponse.new(success: false, error: "Timeout: #{e.message}")
  end
  
  private
  
  def connection
    @connection ||= Faraday.new(url: @base_url) do |f|
      f.request :json
      f.response :json
      f.adapter Faraday.default_adapter
      f.options.timeout = @timeout
    end
  end
  
  def headers
    token = @integration.current_token
    {
      'Content-Type' => 'application/json',
      'Authorization' => "Bearer #{token.decrypt_value}"
    }
  end
end
```

### ğŸ“Š Database Considerations

#### ğŸ—‚ï¸ Indexing Strategy
```sql
-- db/migrate/add_performance_indexes.rb
class AddPerformanceIndexes < ActiveRecord::Migration[8.0]
  def change
    add_index :subscriptions, [:status, :created_at]
    add_index :subscriptions, [:integration_id, :status]
    add_index :subscriptions, :cpf, using: :hash
    add_index :subscription_events, [:subscription_id, :created_at]
    add_index :integration_tokens, [:integration_id, :valid_until]
    
    # Partial indexes for common queries
    add_index :subscriptions, :checked_at, 
              where: "status = 'sent'", 
              name: 'idx_subscriptions_sent_checked_at'
  end
end
```

#### ğŸ”’ Security Enhancements
```ruby
# app/models/concerns/encryptable.rb
module Encryptable
  extend ActiveSupport::Concern
  
  included do
    encrypts :cpf, deterministic: true
    encrypts :value, deterministic: false  # for tokens
  end
end

# config/application.rb
config.force_ssl = true  # in production
config.active_record.encryption.primary_key = ENV['AR_ENCRYPTION_PRIMARY_KEY']
config.active_record.encryption.deterministic_key = ENV['AR_ENCRYPTION_DETERMINISTIC_KEY']
```

### ğŸš€ Deployment & Operations

#### ğŸ“ˆ Monitoring & Metrics
```ruby
# app/controllers/health_controller.rb
class HealthController < ApplicationController
  def check
    render json: {
      status: 'healthy',
      timestamp: Time.current,
      database: database_healthy?,
      redis: redis_healthy?,
      queue: queue_healthy?
    }
  end
  
  private
  
  def database_healthy?
    ActiveRecord::Base.connection.execute('SELECT 1')
    true
  rescue => e
    false
  end
end

# config/schedule.rb (usando whenever gem)
every 5.minutes do
  runner "CheckerJob.perform_later"
end

every 1.hour do
  runner "RegisterCronJob.perform_later"
end

every 1.day, at: '2:00 am' do
  runner "CleanupOldEventsJob.perform_later"
end
```

#### ğŸ”§ Configuration Management
```yaml
# config/database.yml
production:
  adapter: postgresql
  host: <%= ENV['DB_HOST'] %>
  database: <%= ENV['DB_NAME'] %>
  username: <%= ENV['DB_USER'] %>
  password: <%= ENV['DB_PASSWORD'] %>
  pool: <%= ENV['DB_POOL'] || 25 %>
  timeout: 5000
  
# config/environments/production.rb
config.active_job.queue_adapter = :solid_queue
config.cache_store = :solid_cache_store
config.log_level = :info
config.force_ssl = true
```

### ğŸ§ª Testing Strategy

#### ğŸ” RSpec Configuration
```ruby
# spec/services/register_sync_service_spec.rb
RSpec.describe RegisterSyncService do
  describe '#call' do
    let(:integration) { create(:integration) }
    let(:subscription) { create(:subscription, :pending, integration: integration) }
    let(:service) { described_class.new(subscription) }
    
    context 'when subscription passes filters' do
      before { allow_any_instance_of(IntegrationFilter).to receive(:apply).and_return(true) }
      
      it 'sends subscription to institution' do
        expect { service.call }.to change { subscription.reload.status }.to('sent')
      end
      
      it 'creates a subscription event' do
        expect { service.call }.to change { SubscriptionEvent.count }.by(1)
      end
    end
  end
end

# spec/factories/subscriptions.rb
FactoryBot.define do
  factory :subscription do
    association :integration
    association :integration_filter
    order_id { Faker::Number.unique.number(digits: 8) }
    origin { 'quero_bolsa' }
    cpf { Faker::IDNumber.valid }
    payload { { name: Faker::Name.name, course: Faker::Educator.course_name } }
    status { 'pending' }
    
    trait :sent do
      status { 'sent' }
      sent_at { 1.hour.ago }
    end
  end
end
```

## Outras docs

- PÃ¡gina do produto: https://www.notion.so/quero
- [Anubis Docs](https://github.com/quero-edu/anubis/tree/main/docs)

